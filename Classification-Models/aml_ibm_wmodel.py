# -*- coding: utf-8 -*-
"""AML_IBM_wmodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sHy77uJHdR_WGR3eVspvulVs5lu7mzg_
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier #random forest
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score #ölçüm metrikleri
import matplotlib.pyplot as plt #matplotlib
import seaborn as sns #seaborn
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report #bilmiyom
from matplotlib import rc #bunu da
import itertools #bunu da
from sklearn.model_selection import GridSearchCV, cross_validate, RandomizedSearchCV, validation_curve #CV
######################################################
import lightgbm as lgb #lightgbm
from lightgbm import LGBMClassifier, LGBMRegressor
from sklearn.model_selection import cross_val_predict
from xgboost import XGBClassifier
from imblearn.under_sampling import RandomUnderSampler

df = pd.read_csv("/content/df_with_ohe.csv")

df.drop("Unnamed: 0", axis=1, inplace=True)

df.columns = df.columns.str.replace(' ', '_')

df.columns

pd.set_option('display.max_columns', None)
pd.set_option('display.width', 170)
pd.set_option('display.max_rows', None)
pd.set_option('display.float_format', lambda x: '%.3f' % x)

# Hedef değişkeni ayırma
y = df["Is_Laundering"]

# Bağımsız değişkenleri ayırma
X = df.drop(["Is_Laundering","gap_ratio","min_time_gap","date_half_start","Payment_Format_Bitcoin","most_active_time_Evening","most_active_time_Morning","weekday_6","weekday_5","weekday_1","weekday_2","day","hour"], axis=1)

undersampler = RandomUnderSampler()

X,y=undersampler.fit_resample(X,y)

#drop_list = ["gap_ratio","min_time_gap","date_half_start","Payment_Format_Bitcoin","most_active_time_Evening","most_active_time_Morning","weekday_6","weekday_5","weekday_1","weekday_2","day","hour"]

"""xgb_model = XGBClassifier(
    scale_pos_weight=980,  # ← DENGESİZLİK PARAMETRESİ
    random_state=42,
    n_jobs=-1
)

## Random Forest

---
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=17,stratify=y)

rdm_model = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)

rdm_model.fit(X_train, y_train)



y_pred = rdm_model.predict(X_test)
y_proba = rdm_model.predict_proba(X_test)[:, 1]

print(f"Accuracy: {round(accuracy_score(y_pred, y_test), 2)}")
print(f"Recall: {round(recall_score(y_pred,y_test),2)}")
print(f"Precision: {round(precision_score(y_pred,y_test), 2)}")
print(f"F1: {round(f1_score(y_pred,y_test), 2)}")
print(f"Auc: {round(roc_auc_score(y_pred,y_test), 2)}")

Accuracy: 0.94
Recall: 0.96
Precision: 0.93
F1: 0.94
Auc: 0.94

#cv_results_rdm = cross_validate(rdm_model, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc", "recall", "precision"])

# print(cv_results_rdm['test_accuracy'].mean())
# print(cv_results_rdm['test_f1'].mean())
# print(cv_results_rdm['test_roc_auc'].mean())
# print(cv_results_rdm['test_recall'].mean())
# print(cv_results_rdm['test_precision'].mean())

# def plot_confusion_matrix(cm, classes,
#                           title='Confusion matrix',
#                           cmap=plt.cm.Blues):
#     plt.rcParams.update({'font.size': 19})
#     plt.imshow(cm, interpolation='nearest', cmap=cmap)
#     plt.title(title,fontdict={'size':'16'})
#     plt.colorbar()
#     tick_marks = np.arange(len(classes))
#     plt.xticks(tick_marks, classes, rotation=45,fontsize=12,color="blue")
#     plt.yticks(tick_marks, classes,fontsize=12,color="blue")
#     rc('font', weight='bold')
#     fmt = '.1f'
#     thresh = cm.max()
#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
#         plt.text(j, i, format(cm[i, j], fmt),
#                  horizontalalignment="center",
#                  color="red")

#     plt.ylabel('True label',fontdict={'size':'16'})
#     plt.xlabel('Predicted label',fontdict={'size':'16'})
#     plt.tight_layout()

# plot_confusion_matrix(confusion_matrix(y_test, y_pred=y_pred), classes=['Non Launder','Launder'],
#                       title='Confusion matrix')

"""## LightGBM Modeli"""

# lgbm_model = LGBMClassifier(
#     is_unbalance=True,         # ← Azınlık sınıfını otomatik ağırlıklandırır
#     # VEYA
#     # class_weight='balanced', # alternatif olarak da kullanılabilir
#     random_state=42,
#     n_jobs=-1
# )

# df.head()

# df.columns

"""## LGBM

---


"""

# cv_results = cross_validate(lgbm_model, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc", "recall", "precision"])

# print(cv_results['test_accuracy'].mean())
# print(cv_results['test_f1'].mean())
# print(cv_results['test_roc_auc'].mean())
# print(cv_results['test_recall'].mean())
# print(cv_results['test_precision'].mean())

# def plot_confusion_matrix(cm_or_y, y_pred=None, classes=('Non Launder','Launder'),
#                           title='Confusion matrix', cmap=plt.cm.Blues,
#                           normalize=False, labels=None, fmt=None):
#     """
#     cm_or_y:
#         - np.array/list: hazır confusion matrix (veya fold bazlı cm listesi)
#         - y_true (np.array/pd.Series): eğer y_pred de verilirse matris fonksiyon içinde hesaplanır
#     y_pred:
#         - y_true ile birlikte verildiğinde confusion matrix'i içeride hesaplar (CV OOF tahminleri için ideal)
#     classes:
#         - Eksenlerde gösterilecek sınıf isimleri
#     normalize:
#         - True ise satır bazlı normalize edilmiş oranları çizer
#     labels:
#         - confusion_matrix hesaplanırken sınıf sırası (ör: [0,1])
#     fmt:
#         - Hücre yazı formatı; None ise normalize'a göre otomatik seçilir
#     """

#     # 1) Confusion matrix'i hazırla
#     if y_pred is not None:
#         cm = confusion_matrix(cm_or_y, y_pred, labels=labels)
#     else:
#         cm = cm_or_y

#     # Liste/tuple ise (ör. her fold’un cm’si) topla
#     if isinstance(cm, (list, tuple)):
#         cm = np.sum(np.stack(cm, axis=0), axis=0)

#     cm = np.asarray(cm)

#     # 2) Normalize edilecek gösterim matrisi
#     if normalize:
#         with np.errstate(invalid='ignore', divide='ignore'):
#             cm_disp = cm.astype(float) / cm.sum(axis=1, keepdims=True)
#         cm_disp = np.nan_to_num(cm_disp)  # 0 bölümlerine karşı
#         default_fmt = '.2f'
#     else:
#         cm_disp = cm
#         default_fmt = 'd'

#     if fmt is None:
#         fmt = default_fmt

#     # 3) Çizim
#     plt.rcParams.update({'font.size': 19})
#     plt.imshow(cm_disp, interpolation='nearest', cmap=cmap)
#     plt.title(title, fontdict={'size': '16'})
#     plt.colorbar()
#     tick_marks = np.arange(len(classes))
#     plt.xticks(tick_marks, classes, rotation=45, fontsize=12, color="blue")
#     plt.yticks(tick_marks, classes, fontsize=12, color="blue")
#     rc('font', weight='bold')

#     # Hücre yazıları
#     for i, j in itertools.product(range(cm_disp.shape[0]), range(cm_disp.shape[1])):
#         plt.text(j, i, format(cm_disp[i, j], fmt),
#                  horizontalalignment="center",
#                  color="red")

#     plt.ylabel('True label', fontdict={'size': '16'})
#     plt.xlabel('Predicted label', fontdict={'size': '16'})
#     plt.tight_layout()

# y_pred_cv = cross_val_predict(lgbm_model, X, y, cv=5, n_jobs=-1)
# plot_confusion_matrix(y, y_pred_cv,
#                       classes=['Non Launder','Launder'],
#                       title='CV Confusion Matrix', normalize=False, labels=[0,1])

"""## XGBOOST"""

# xgb_model = XGBClassifier(
#     scale_pos_weight=980,  # ← DENGESİZLİK PARAMETRESİ
#     random_state=42,
#     n_jobs=-1
# )

# cv_results_xgbm = cross_validate(xgb_model, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc", "precision", "recall"])

# print(cv_results_xgbm['test_accuracy'].mean())
# print(cv_results_xgbm['test_f1'].mean())
# print(cv_results_xgbm['test_roc_auc'].mean())
# print(cv_results_xgbm['test_recall'].mean())
# print(cv_results_xgbm['test_precision'].mean())

"""## Hiperparametre optimizasyonu

Random Forest
"""

# def plot_importance(model, features, num=len(X), save=False):
#     feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})
#     plt.figure(figsize=(10, 10))
#     sns.set(font_scale=1)
#     sns.barplot(x="Value", y="Feature", data=feature_imp.sort_values(by="Value",
#                                                                      ascending=False)[0:num])
#     plt.title('Features')
#     plt.tight_layout()
#     plt.show()
#     if save:
#         plt.savefig('importances.png')

rf_params = {"min_samples_split": [2, 5, 8, 15],
             "n_estimators": [100, 200, 500],
             "max_depth": [5, 8, None],
             "max_features": [5, 7, "auto"]}



cv_random_forest = GridSearchCV(rdm_model, rf_params, cv=3, n_jobs=-1, verbose=True).fit(X,y)

cv_random_forest.best_params_

cv_random_forest.best_params_

"""**En iyi parametreler:**
{'max_depth': None,

 'max_features': 7,

 'min_samples_split': 2,

 'n_estimators': 200}

{'max_depth': None,
 'max_features': 7,
 'min_samples_split': 2,
 'n_estimators': 200}

Eğer test train split yapacaksak
"""

rdm_final_split = rdm_model.set_params(**cv_random_forest.best_params_, class_weight='balanced', random_state=42, n_jobs=-1).fit(X_train, y_train)

y_pred_final = rdm_final_split.predict(X_test)
y_proba_final = rdm_final_split.predict_proba(X_test)[:, 1]

print(classification_report(y_test, y_pred_final))

print(f"Accuracy: {round(accuracy_score(y_test, y_pred_final), 2)}")
print(f"Recall: {round(recall_score(y_test, y_pred_final), 2)}")
print(f"Precision: {round(precision_score(y_test, y_pred_final), 2)}")
print(f"F1: {round(f1_score(y_test, y_pred_final), 2)}")
print(f"Auc: {round(roc_auc_score(y_test, y_pred_final), 2)}")

print(classification_report(y_test, y_pred_final))

def plot_confusion_matrix(cm, classes,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):

    plt.rcParams.update({'font.size': 19})
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title,fontdict={'size':'16'})
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45,fontsize=12,color="blue")
    plt.yticks(tick_marks, classes,fontsize=12,color="blue")
    rc('font', weight='bold')
    fmt = '.1f'
    thresh = cm.max()
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="red")

    plt.ylabel('True label',fontdict={'size':'16'})
    plt.xlabel('Predicted label',fontdict={'size':'16'})
    plt.tight_layout()

plot_confusion_matrix(confusion_matrix(y_test, y_pred=y_pred_final), classes=['Non Fraud','Fraud'],
                      title='Confusion matrix')

"""Eğer cros validation kullanacaksak"""

rdm_final_cv = rdm_model.set_params(**cv_random_forest.best_params_, class_weight='balanced', random_state=42, n_jobs=-1).fit(X,y)

cv_results = cross_validate(rdm_final_cv, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc","recall","precision"])

print("accuracy:  ",cv_results['test_accuracy'].mean())
print("f1 score:  ",cv_results['test_f1'].mean())
print("roc auc:  ",cv_results['test_roc_auc'].mean())
print("recall:  ",cv_results['test_recall'].mean())
print("precision:  ",cv_results['test_precision'].mean())

print(classification_report(cv_results, y_pred))

"""Kara para nedir? Tespiti neden ve kimler için önemlidir? Önlenmezse oluşabilecek problemler nelerdir?
Veri seti hikayesi?
Kara para akla
"""
